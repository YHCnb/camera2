class CameraHelper(private val context: Context, private val activity: FragmentActivity) {
    private var cameraId: String = "-1"

    private var onPreviewSizeListener: OnPreviewSizeListener? = null
    private var onPreviewListener: OnPreviewListener? = null


    /** Detects, characterizes, and connects to a CameraDevice (used for all camera operations) */
    private lateinit var cameraManager: CameraManager

    /** [CameraCharacteristics] corresponding to the provided Camera ID */
    private lateinit var characteristics: CameraCharacteristics

    /** Readers used as buffers for camera still shots */
    private lateinit var imageReader: ImageReader
    /** 将图像数据存储在队列中，待处理程序准备好后再进行处理,可以避免图像数据的丢失 */
    val imageQueue = ArrayBlockingQueue<Image>(IMAGE_BUFFER_SIZE)

    /** [HandlerThread] where all camera operations run */
    private var cameraThread: HandlerThread? = null

    /** [Handler] corresponding to [cameraThread] */
    private var cameraHandler: Handler? = null

    /** The [CameraDevice] that will be opened in this fragment */
    private var camera: CameraDevice? = null

    /** Internal reference to the ongoing [CameraCaptureSession] configured with our parameters */
    private var cameraCaptureSession: CameraCaptureSession? = null

    /** Live data listener for changes in the device orientation relative to the camera 横屏与竖屏检测 */
    private lateinit var relativeOrientation: OrientationLiveData

    /** 支持的awb模式,以及目前的模式 */
    private val awbModes = ArrayList<Int>()
    private var currentAWB = -1
    private var currentAWBIdx = -1

    /** Flag whether we should restart preview after an extension switch. */
    private var restartPreview = false

    /** SurfaceTexture  */
    private var surfaceTexture: SurfaceTexture? = null
    /** The [Size] of camera preview. */
    private lateinit var previewSize: Size
    /** [CaptureRequest.Builder] for the camera preview */
    private var previewRequestBuilder: CaptureRequest.Builder? = null
    /** [CaptureRequest] generated by [.mPreviewRequestBuilder] */
    private var previewRequest: CaptureRequest? = null
    /**  surfaceTexture的surface */
    private var previewSurface: Surface? = null

    private var minBrightnessRange:Int =0
    private var maxBrightnessRange:Int =0
    private var brightness:Int = 0
    private var contrast:Int = 0
    private var channels : Array<FloatArray?> = null


    fun getCameraId(): Int {
        return cameraId.toInt()
    }

    fun getSize(): Size {
        return previewSize
    }

    @SuppressLint("MissingPermission")
    fun openCamera(mSurfaceTexture: SurfaceTexture,width:Int, height:Int) {
        surfaceTexture = mSurfaceTexture
        startBackgroundThread()

        cameraManager = context.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        //设置预览图像的大小，surfaceview的大小。
        setUpCameraOutputs(width,height)
        try {
            if (context.checkSelfPermission(Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED) {
                // TODO: Consider calling
                //    Activity#requestPermissions
                // here to request the missing permissions, and then overriding
                //   public void onRequestPermissionsResult(int requestCode, String[] permissions,
                //                                          int[] grantResults)
                // to handle the case where the user grants the permission. See the documentation
                // for Activity#requestPermissions for more details.
                return
            }
            cameraManager.openCamera(cameraId, mStateCallback, cameraHandler)
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        }
    }

    /**
     * [CameraDevice.StateCallback] is called when [CameraDevice] changes its state.
     */
    private val mStateCallback: CameraDevice.StateCallback = object : CameraDevice.StateCallback() {
        override fun onOpened(cameraDevice: CameraDevice) {
            // This method is called when the camera is opened.  We start camera preview here.
            camera = cameraDevice
            createCameraPreviewSession() //相机打开了就创建session
        }

        override fun onDisconnected(cameraDevice: CameraDevice) {
            cameraDevice.close()
            camera = null
        }

        override fun onError(cameraDevice: CameraDevice, error: Int) {
            cameraDevice.close()
            camera = null
        }
    }

    /**
     * Closes the current [CameraDevice].
     */
    fun closeCamera() {
        cameraCaptureSession?.close()
        cameraCaptureSession = null
        camera?.close()
        camera = null
        surfaceTexture?.release()
        surfaceTexture = null
        stopBackgroundThread()
    }

    /**
     * Starts a background thread and its [Handler].
     */
    private fun startBackgroundThread() {
        cameraThread = HandlerThread("cameraThread")
        cameraThread!!.start()
        cameraHandler = Handler(cameraThread!!.looper)
    }

    /**
     * Stops the background thread and its [Handler].
     */
    private fun stopBackgroundThread() {
        cameraThread?.quitSafely()
        try {
            cameraThread?.join()
            cameraThread = null
            cameraHandler = null
        } catch (e: InterruptedException) {
            e.printStackTrace()
        }
    }

    /** Sets up member variables related to camera. 获取一些必要的量，为打开相机做准备*/
    private fun setUpCameraOutputs(width:Int, height:Int) {
        try {
            for (id :String in cameraManager.cameraIdList) {
                val cha = cameraManager.getCameraCharacteristics(id)
                // 选择前摄像头
                val facing = cha.get(CameraCharacteristics.LENS_FACING)
                if (facing != null && facing != CameraCharacteristics.LENS_FACING_FRONT) {
                    continue
                }
                cha.get(
                    CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP
                ) ?: continue

                cameraId = id
                characteristics = cha

                //获取所有支持的AWB模式
                awbModes.addAll(characteristics.get(CameraCharacteristics.CONTROL_AWB_AVAILABLE_MODES)!!.asList())
                if (currentAWB == -1) {
                    currentAWB = awbModes[0]
                    currentAWBIdx = 0
                }

                val windowManager = context.getSystemService(Context.WINDOW_SERVICE) as WindowManager

                val displayMetrics = DisplayMetrics()
                windowManager.defaultDisplay.getRealMetrics(displayMetrics)

                //设置预览尺寸
                val rotatedPreviewWidth: Int = width
                val rotatedPreviewHeight: Int = height
                val maxPreviewWidth = context.resources.displayMetrics.widthPixels
                val maxPreviewHeight = context.resources.displayMetrics.heightPixels
                val map = characteristics.get(
                    CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP)!!
                val largest = map.getOutputSizes(PIXEL_FORMAT_PHOTO)
                    .maxByOrNull { it.height * it.width }!!
                previewSize = chooseOptimalSize(
                    map.getOutputSizes(SurfaceTexture::class.java),
                    rotatedPreviewWidth, rotatedPreviewHeight,
                    maxPreviewWidth, maxPreviewHeight,
                    largest
                )
                onPreviewSizeListener?.onSize(previewSize.width, previewSize.height)
                //创建imageReader
                imageReader = ImageReader.newInstance(
                    previewSize.width, previewSize.height, PIXEL_FORMAT_PHOTO, IMAGE_BUFFER_SIZE
                )
                //录像
                imageReader.setOnImageAvailableListener(
                    onImageAvailableListener,
                    cameraHandler
                )
            }
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        } catch (e: NullPointerException) {
        }
    }

    /** Creates a new [CameraCaptureSession] for camera preview. */
    private fun createCameraPreviewSession() {
        try {
            // This is the output Surface we need to start preview.
            surfaceTexture!!.setDefaultBufferSize(previewSize.width, previewSize.height)
            previewSurface = Surface(surfaceTexture)

            // We set up a CaptureRequest.Builder with the output Surface.
            previewRequestBuilder = camera!!.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW)
            previewRequestBuilder!!.addTarget(previewSurface!!)
            previewRequestBuilder!!.addTarget(imageReader.surface)

            // Here, we create a CameraCaptureSession for camera preview.
            camera!!.createCaptureSession(
                listOf(previewSurface, imageReader.surface),
                object : CameraCaptureSession.StateCallback() {
                    override fun onConfigured(session: CameraCaptureSession) {
                        // The camera is already closed
                        if (null == camera) {
                            return
                        }

                        // When the session is ready, we start displaying the preview.
                        cameraCaptureSession = session
                        try {
                            // 对焦模式
                            previewRequestBuilder!!.set(
                                CaptureRequest.CONTROL_AF_MODE,
                                CaptureRequest.CONTROL_AF_MODE_AUTO
                            )
                            // 白平衡
                            previewRequestBuilder!!.set(
                                CaptureRequest.CONTROL_AWB_MODE,
                                currentAWB
                            )
                            // TODO
                            previewRequestBuilder!!.set(
                                CaptureRequest.COLOR_CORRECTION_MODE,
                                CaptureRequest.COLOR_CORRECTION_MODE_TRANSFORM_MATRIX
                            )
                            //降噪算法操作模式
                            previewRequestBuilder!!.set(CaptureRequest.NOISE_REDUCTION_MODE, CaptureRequest.NOISE_REDUCTION_MODE_FAST)
                            // 亮度修改
                            minBrightnessRange = characteristics.get(CONTROL_AE_COMPENSATION_RANGE)!!.lower
                            maxBrightnessRange = characteristics.get(CONTROL_AE_COMPENSATION_RANGE)!!.upper
                            setBrightness(brightness)
                            // 对比度修改
                            previewRequestBuilder!!.set(CaptureRequest.TONEMAP_MODE, CaptureRequest.TONEMAP_MODE_CONTRAST_CURVE) //TONEMAP模式选择
                            val tc: TonemapCurve? = previewRequestBuilder!![CaptureRequest.TONEMAP_CURVE]
                            if (tc != null) {
                                channels = arrayOfNulls<FloatArray>(3)
                                for (chanel in TonemapCurve.CHANNEL_RED..TonemapCurve.CHANNEL_BLUE) {
                                    val array = FloatArray(tc.getPointCount(chanel) * 2)
                                    tc.copyColorCurve(chanel, array, 0)
                                    channels[chanel] = array
                                }
                            }
                            setContrast(contrast)


                            previewRequest = previewRequestBuilder!!.build()
                            cameraCaptureSession!!.setRepeatingRequest(
                                previewRequest!!,
                                captureCallbackVideo, cameraHandler
                            )
                        } catch (e: CameraAccessException) {
                            e.printStackTrace()
                        }
                    }
                    override fun onConfigureFailed(
                        session: CameraCaptureSession
                    ) {
                        Log.d(TAG, "onConfigureFailed: ")
                    }
                }, null
            )
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        }
    }

    /** [CameraCaptureSession.CaptureCallback] 录像模式不做处理，为空*/
    private val captureCallbackVideo: CameraCaptureSession.CaptureCallback =
        object : CameraCaptureSession.CaptureCallback() {
            override fun onCaptureProgressed(
                session: CameraCaptureSession,
                request: CaptureRequest,
                partialResult: CaptureResult
            ) {
            }

            override fun onCaptureCompleted(
                session: CameraCaptureSession,
                request: CaptureRequest,
                result: TotalCaptureResult
            ) {
            }
        }

    /** 处理YUV格式图像，并传给onPreviewListener用于人脸检测 */
    private val onImageAvailableListener = ImageReader.OnImageAvailableListener { reader ->
        val image = reader.acquireNextImage() ?: return@OnImageAvailableListener
        val planes = image.planes
        val width = image.width
        val height = image.height
        val yBytes = ByteArray(width * height)
        val uBytes = ByteArray(width * height / 4)
        val vBytes = ByteArray(width * height / 4)
        val i420 = ByteArray(width * height * 3 / 2)
        for (i in planes.indices) {
            var dstIndex = 0
            val uIndex = 0
            val vIndex = 0
            val pixelStride = planes[i].pixelStride
            val rowStride = planes[i].rowStride
            val buffer = planes[i].buffer
            val bytes = ByteArray(buffer.capacity())
            buffer[bytes]
            var srcIndex = 0
            when (i) {
                0 -> {
                    for (j in 0 until height) {
                        System.arraycopy(bytes, srcIndex, yBytes, dstIndex, width)
                        srcIndex += rowStride
                        dstIndex += width
                    }
                }
                1 -> {
                    for (j in 0 until height / 2) {
                        for (k in 0 until width / 2) {
                            uBytes[dstIndex++] = bytes[srcIndex]
                            srcIndex += pixelStride
                        }
                        if (pixelStride == 2) {
                            srcIndex += rowStride - width
                        } else if (pixelStride == 1) {
                            srcIndex += rowStride - width / 2
                        }
                    }
                }
                2 -> {
                    for (j in 0 until height / 2) {
                        for (k in 0 until width / 2) {
                            vBytes[dstIndex++] = bytes[srcIndex]
                            srcIndex += pixelStride
                        }
                        if (pixelStride == 2) {
                            srcIndex += rowStride - width
                        } else if (pixelStride == 1) {
                            srcIndex += rowStride - width / 2
                        }
                    }
                }
            }
            System.arraycopy(yBytes, 0, i420, 0, yBytes.size)
            System.arraycopy(uBytes, 0, i420, yBytes.size, uBytes.size)
            System.arraycopy(vBytes, 0, i420, yBytes.size + uBytes.size, vBytes.size)
            onPreviewListener?.onPreviewFrame(i420, i420.size)
        }
        image.close()
    }

    fun setBrightness(value: Int){
        val brightnessValue = (minBrightnessRange + (maxBrightnessRange - minBrightnessRange) * (brightness / 100f)).toInt()
        previewRequestBuilder!!.set(
            CaptureRequest.CONTROL_AE_EXPOSURE_COMPENSATION,
            brightnessValue
        )
        // TODO 重新请求过
    }

    fun setContrast(value:Int){
        if (channels == null || contrast > 100 || contrast < 0) {
            return
        }

        val contrast: Float =
            1* (value / 100f)

        val newValues = arrayOfNulls<FloatArray>(3)
        for (chanel in TonemapCurve.CHANNEL_RED..TonemapCurve.CHANNEL_BLUE) {
            val array = FloatArray(channels[chanel]!!.size)
            System.arraycopy(channels[chanel]!!, 0, array, 0, array.size)
            for (i in array.indices) {
                array[i] *= contrast
            }
            newValues[chanel] = array
        }
        val tc = TonemapCurve(
            newValues[TonemapCurve.CHANNEL_RED],
            newValues[TonemapCurve.CHANNEL_GREEN],
            newValues[TonemapCurve.CHANNEL_BLUE]
        )
        previewRequestBuilder!!.set(CaptureRequest.TONEMAP_CURVE, tc)
    }

    fun setPreviewSizeListener(onPreviewSizeListener: OnPreviewSizeListener?) {
        this.onPreviewSizeListener = onPreviewSizeListener
    }

    fun setOnPreviewListener(onPreviewListener: OnPreviewListener?) {
        this.onPreviewListener = onPreviewListener
    }

    fun switchAWB(){
        println(awbModes.size)
        currentAWBIdx = (currentAWBIdx + 1) % awbModes.size
        currentAWB = awbModes[currentAWBIdx]
        previewRequestBuilder!!.set(
            CaptureRequest.CONTROL_AWB_MODE,
            currentAWB
        )
        previewRequest = previewRequestBuilder!!.build()
        cameraCaptureSession!!.setRepeatingRequest(
            previewRequest!!,
            captureCallbackVideo, cameraHandler
        )
    }

    fun getCurrentAWB(): Int {
        return currentAWB
        characteristics
    }

    fun getCharacteristics(): CameraCharacteristics {
        return characteristics
    }

    interface OnPreviewSizeListener {
        fun onSize(width: Int, height: Int)
    }

    interface OnPreviewListener {
        fun onPreviewFrame(data: ByteArray?, len: Int)
    }

    companion object {
        private val TAG = CameraFragment::class.java.simpleName
        /** 照片格式 */
        private const val PIXEL_FORMAT_PHOTO = ImageFormat.JPEG
        /** 视频格式 */
        private const val PIXEL_FORMAT_VIDEO = ImageFormat.YUV_420_888

        /** Maximum number of images that will be held in the reader's buffer */
        private const val IMAGE_BUFFER_SIZE: Int = 3

        /** Maximum time allowed to wait for the result of an image capture */
        private const val IMAGE_CAPTURE_TIMEOUT_MILLIS: Long = 5000

        /** Helper data class used to hold capture metadata with their associated image */
        data class CombinedCaptureResult(
            val image: Image,
            val metadata: CaptureResult,
            val orientation: Int,
            val format: Int
        ) : Closeable {
            override fun close() = image.close()
        }


        private fun chooseOptimalSize(
            choices: Array<Size>, textureViewWidth: Int,
            textureViewHeight: Int, maxWidth: Int, maxHeight: Int, aspectRatio: Size
        ): Size {

            // Collect the supported resolutions that are at least as big as the preview Surface
            val bigEnough: MutableList<Size> = ArrayList()
            // Collect the supported resolutions that are smaller than the preview Surface
            val notBigEnough: MutableList<Size> = ArrayList()
            val w = aspectRatio.width
            val h = aspectRatio.height
            for (option in choices) {
                if (option.width <= maxWidth && option.height <= maxHeight && option.height == option.width * h / w) {
                    if (option.width >= textureViewWidth &&
                        option.height >= textureViewHeight
                    ) {
                        bigEnough.add(option)
                    } else {
                        notBigEnough.add(option)
                    }
                }
            }

            // Pick the smallest of those big enough. If there is no one big enough, pick the
            // largest of those not big enough.
            return when {
                bigEnough.size > 0 -> {
                    Collections.min(bigEnough, CompareSizesByArea())
                }
                notBigEnough.size > 0 -> {
                    Collections.max(notBigEnough, CompareSizesByArea())
                }
                else -> {
                    Log.e("Camera2Helper", "Couldn't find any suitable preview size")
                    choices[0]
                }
            }
        }

        internal class CompareSizesByArea : Comparator<Size> {
            override fun compare(lhs: Size, rhs: Size): Int {
                // We cast here to ensure the multiplications won't overflow
                return java.lang.Long.signum(
                    lhs.width.toLong() * lhs.height -
                            rhs.width.toLong() * rhs.height
                )
            }
        }
    }
}
