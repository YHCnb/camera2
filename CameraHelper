class CameraHelper(private val context: Context, private val activity: FragmentActivity) {
    private var cameraId: String = "-1"

    private var onPreviewSizeListener: OnPreviewSizeListener? = null
    private var onPreviewListener: OnPreviewListener? = null


    /** Detects, characterizes, and connects to a CameraDevice (used for all camera operations) */
    private lateinit var cameraManager: CameraManager

    /** [CameraCharacteristics] corresponding to the provided Camera ID */
    private lateinit var characteristics: CameraCharacteristics

    /** Readers used as buffers for camera still shots */
    private lateinit var imageReader: ImageReader
    /** 将图像数据存储在队列中，待处理程序准备好后再进行处理,可以避免图像数据的丢失 */
    val imageQueue = ArrayBlockingQueue<Image>(IMAGE_BUFFER_SIZE)

    /** [HandlerThread] where all camera operations run */
    private var cameraThread: HandlerThread? = null

    /** [Handler] corresponding to [cameraThread] */
    private var cameraHandler: Handler? = null

    /** The [CameraDevice] that will be opened in this fragment */
    private var camera: CameraDevice? = null

    /** Internal reference to the ongoing [CameraCaptureSession] configured with our parameters */
    private var cameraCaptureSession: CameraCaptureSession? = null

    /** Live data listener for changes in the device orientation relative to the camera 横屏与竖屏检测 */
    private lateinit var relativeOrientation: OrientationLiveData

    /** 支持的awb模式,以及目前的模式 */
    private val awbModes = ArrayList<Int>()
    private var currentAWB = -1
    private var currentAWBIdx = -1

    /** Flag whether we should restart preview after an extension switch. */
    private var restartPreview = false

    /** SurfaceTexture  */
    private var surfaceTexture: SurfaceTexture? = null
    /** The [Size] of camera preview. */
    private lateinit var previewSize: Size
    /** [CaptureRequest.Builder] for the camera preview */
    private var previewRequestBuilder: CaptureRequest.Builder? = null
    /** [CaptureRequest] generated by [.mPreviewRequestBuilder] */
    private var previewRequest: CaptureRequest? = null


    fun getCameraId(): Int {
        return cameraId.toInt()
    }

    fun getSize(): Size {
        return previewSize
    }

    @SuppressLint("MissingPermission")
    fun openCamera(mSurfaceTexture: SurfaceTexture,width:Int, height:Int) {
        surfaceTexture = mSurfaceTexture
        startBackgroundThread()

        cameraManager = context.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        //设置预览图像的大小，surfaceview的大小。
        setUpCameraOutputs(width,height)
        try {
            if (context.checkSelfPermission(Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED) {
                // TODO: Consider calling
                //    Activity#requestPermissions
                // here to request the missing permissions, and then overriding
                //   public void onRequestPermissionsResult(int requestCode, String[] permissions,
                //                                          int[] grantResults)
                // to handle the case where the user grants the permission. See the documentation
                // for Activity#requestPermissions for more details.
                return
            }
            cameraManager.openCamera(cameraId, mStateCallback, cameraHandler)
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        }
    }

    /**
     * [CameraDevice.StateCallback] is called when [CameraDevice] changes its state.
     */
    private val mStateCallback: CameraDevice.StateCallback = object : CameraDevice.StateCallback() {
        override fun onOpened(cameraDevice: CameraDevice) {
            // This method is called when the camera is opened.  We start camera preview here.
            camera = cameraDevice
            createCameraPreviewSession() //相机打开了就创建session
        }

        override fun onDisconnected(cameraDevice: CameraDevice) {
            cameraDevice.close()
            camera = null
        }

        override fun onError(cameraDevice: CameraDevice, error: Int) {
            cameraDevice.close()
            camera = null
        }
    }

    /**
     * Closes the current [CameraDevice].
     */
    fun closeCamera() {
        cameraCaptureSession?.close()
        cameraCaptureSession = null
        camera?.close()
        camera = null
        surfaceTexture?.release()
        surfaceTexture = null
        stopBackgroundThread()
    }

    /**
     * Starts a background thread and its [Handler].
     */
    private fun startBackgroundThread() {
        cameraThread = HandlerThread("cameraThread")
        cameraThread!!.start()
        cameraHandler = Handler(cameraThread!!.looper)
    }

    /**
     * Stops the background thread and its [Handler].
     */
    private fun stopBackgroundThread() {
        cameraThread?.quitSafely()
        try {
            cameraThread?.join()
            cameraThread = null
            cameraHandler = null
        } catch (e: InterruptedException) {
            e.printStackTrace()
        }
    }

    /** Sets up member variables related to camera. 获取一些必要的量，为打开相机做准备*/
    private fun setUpCameraOutputs(width:Int, height:Int) {
        try {
            for (id :String in cameraManager.cameraIdList) {
                val cha = cameraManager.getCameraCharacteristics(id)
                // 选择前摄像头
                val facing = cha.get(CameraCharacteristics.LENS_FACING)
                if (facing != null && facing != CameraCharacteristics.LENS_FACING_FRONT) {
                    continue
                }
                cha.get(
                    CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP
                ) ?: continue

                cameraId = id
                characteristics = cha

                //获取所有支持的AWB模式
                awbModes.addAll(characteristics.get(CameraCharacteristics.CONTROL_AWB_AVAILABLE_MODES)!!.asList())
                if (currentAWB == -1) {
                    currentAWB = awbModes[0]
                    currentAWBIdx = 0
                }

                val windowManager = context.getSystemService(Context.WINDOW_SERVICE) as WindowManager

                val displayMetrics = DisplayMetrics()
                windowManager.defaultDisplay.getRealMetrics(displayMetrics)

                val widthPixels = displayMetrics.widthPixels / displayMetrics.xdpi
                val heightPixels = displayMetrics.heightPixels / displayMetrics.ydpi
                //设置预览尺寸
                val rotatedPreviewWidth: Int = width
                val rotatedPreviewHeight: Int = height
                val maxPreviewWidth = context.resources.displayMetrics.widthPixels
                val maxPreviewHeight = context.resources.displayMetrics.heightPixels
                val map = characteristics.get(
                    CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP)!!
                val largest = map.getOutputSizes(PIXEL_FORMAT_PHOTO)
                    .maxByOrNull { it.height * it.width }!!
                previewSize = chooseOptimalSize(
                    map.getOutputSizes(SurfaceTexture::class.java),
                    rotatedPreviewWidth, rotatedPreviewHeight,
                    maxPreviewWidth, maxPreviewHeight,
                    largest
                )
                onPreviewSizeListener?.onSize(previewSize.width, previewSize.height)
                //创建imageReader
                imageReader = ImageReader.newInstance(
                    previewSize.width, previewSize.height, PIXEL_FORMAT_PHOTO, IMAGE_BUFFER_SIZE
                )
                //录像
//                imageReader.setOnImageAvailableListener(
//                    onImageAvailableListener,
//                    cameraHandler
//                )
                //照相
                imageReader.setOnImageAvailableListener({ reader ->
                    val image = reader.acquireNextImage()
                    Log.d(TAG, "Image available in queue: ${image.timestamp}")
                    imageQueue.add(image)
                }, cameraHandler)
            }
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        } catch (e: NullPointerException) {
        }
    }

    /**
     * Creates a new [CameraCaptureSession] for camera preview.
     */
    private fun createCameraPreviewSession() {
        try {
            // This is the output Surface we need to start preview.
            surfaceTexture!!.setDefaultBufferSize(previewSize.width, previewSize.height)
            val surface = Surface(surfaceTexture)

            // We set up a CaptureRequest.Builder with the output Surface.
            previewRequestBuilder = camera!!.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW)
            previewRequestBuilder!!.addTarget(surface)
//            previewRequestBuilder!!.addTarget(imageReader.surface) TODO

            // Here, we create a CameraCaptureSession for camera preview.
            camera!!.createCaptureSession(
                listOf(surface, imageReader.surface),
                object : CameraCaptureSession.StateCallback() {
                    override fun onConfigured(session: CameraCaptureSession) {
                        // The camera is already closed
                        if (null == camera) {
                            return
                        }

                        // When the session is ready, we start displaying the preview.
                        cameraCaptureSession = session
                        try {
                            // Auto focus should be continuous for camera preview.
                            previewRequestBuilder!!.set(
                                CaptureRequest.CONTROL_AF_MODE,
                                CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE
                            )
                            previewRequestBuilder!!.set(
                                CaptureRequest.CONTROL_AWB_MODE,
                                currentAWB
                            )
                            previewRequestBuilder!!.set(
                                CaptureRequest.COLOR_CORRECTION_MODE,
                                CaptureRequest.COLOR_CORRECTION_MODE_TRANSFORM_MATRIX
                            )

                            // Flash is automatically enabled when necessary.

                            // Finally, we start displaying the camera preview.
                            previewRequest = previewRequestBuilder!!.build()
                            cameraCaptureSession!!.setRepeatingRequest(
                                previewRequest!!,
                                captureCallbackVideo, cameraHandler
                            )
                        } catch (e: CameraAccessException) {
                            e.printStackTrace()
                        }
                    }
                    override fun onConfigureFailed(
                        session: CameraCaptureSession
                    ) {
                        Log.d(TAG, "onConfigureFailed: ")
                    }
                }, null
            )
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        }
    }

    /**
     * Helper function used to capture a still image using the [CameraDevice.TEMPLATE_STILL_CAPTURE]
     * template. It performs synchronization between the [CaptureResult] and the [Image] resulting
     * from the single capture, and outputs a [CombinedCaptureResult] object.
     */
    suspend fun takePhoto(): CombinedCaptureResult = suspendCoroutine { cont ->

        // Flush any images left in the image reader
        @Suppress("ControlFlowWithEmptyBody")
        while (imageReader.acquireNextImage() != null) {
        }
        // TODO
        submitRequest(
            CameraDevice.TEMPLATE_STILL_CAPTURE,  //表示拍单张照片
            imageReader.surface,   //输出在imageReader上
            false,
            captureCallbackPhoto
        ) { request ->
            request.apply {
//                set(CaptureRequest.CONTROL_ZOOM_RATIO, zoomRatio)
            }
        }
    }

    /** [CameraCaptureSession.CaptureCallback] 录像模式不做处理，为空*/
    private val captureCallbackVideo: CameraCaptureSession.CaptureCallback =
        object : CameraCaptureSession.CaptureCallback() {
            override fun onCaptureProgressed(
                session: CameraCaptureSession,
                request: CaptureRequest,
                partialResult: CaptureResult
            ) {
            }

            override fun onCaptureCompleted(
                session: CameraCaptureSession,
                request: CaptureRequest,
                result: TotalCaptureResult
            ) {
            }
        }

    /** [CameraCaptureSession.CaptureCallback] 照相模式下*/
    private val captureCallbackPhoto : CameraCaptureSession.CaptureCallback =
        object : CameraCaptureSession.CaptureCallback(){

            override fun onCaptureCompleted(
                session: CameraCaptureSession,
                request: CaptureRequest,
                result: TotalCaptureResult
            ) {
                super.onCaptureCompleted(session, request, result)
                val resultTimestamp = result.get(CaptureResult.SENSOR_TIMESTAMP)
                Log.d(TAG, "Capture result received: $resultTimestamp")

                // Set a timeout in case image captured is dropped from the pipeline
                val exc = TimeoutException("Image dequeuing took too long")
                val timeoutRunnable = Runnable { cont.resumeWithException(exc) }
                cameraHandler!!.postDelayed(timeoutRunnable, IMAGE_CAPTURE_TIMEOUT_MILLIS)

                // Loop in the coroutine's context until an image with matching timestamp comes
                // We need to launch the coroutine context again because the callback is done in
                //  the handler provided to the `capture` method, not in our coroutine context
                @Suppress("BlockingMethodInNonBlockingContext")
                runBlocking(cont.context){
                    while (true) {

                        // Dequeue images while timestamps don't match
                        val image = imageQueue.take()
                        // TODO(owahltinez): b/142011420
                        // if (image.timestamp != resultTimestamp) continue
                        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.Q &&
                            image.format != ImageFormat.DEPTH_JPEG &&
                            image.timestamp != resultTimestamp) continue
                        Log.d(TAG, "Matching image dequeued: ${image.timestamp}")

                        // Unset the image reader listener
                        cameraHandler!!.removeCallbacks(timeoutRunnable)
                        imageReader.setOnImageAvailableListener(null, null)

                        // Clear the queue of images, if there are left
                        while (imageQueue.size > 0) {
                            imageQueue.take().close()
                        }

                        // Compute EXIF orientation metadata
                        val rotation = relativeOrientation.value ?: 0
                        val mirrored = characteristics.get(CameraCharacteristics.LENS_FACING) ==
                                CameraCharacteristics.LENS_FACING_FRONT
                        val exifOrientation = computeExifOrientation(rotation, mirrored)

                        // Build the result and resume progress
                        cont.resume(
                            CombinedCaptureResult(
                                image, result, exifOrientation, imageReader.imageFormat
                            )
                        )
                    }
                }
            }
        }

    /** 用于录像时处理YUV格式图像的Listener */
    private val onImageAvailableListenerVideo = ImageReader.OnImageAvailableListener { reader ->
        val image = reader.acquireNextImage() ?: return@OnImageAvailableListener
        val planes = image.planes
        val width = image.width
        val height = image.height
        val yBytes = ByteArray(width * height)
        val uBytes = ByteArray(width * height / 4)
        val vBytes = ByteArray(width * height / 4)
        val i420 = ByteArray(width * height * 3 / 2)
        for (i in planes.indices) {
            var dstIndex = 0
            val uIndex = 0
            val vIndex = 0
            val pixelStride = planes[i].pixelStride
            val rowStride = planes[i].rowStride
            val buffer = planes[i].buffer
            val bytes = ByteArray(buffer.capacity())
            buffer[bytes]
            var srcIndex = 0
            when (i) {
                0 -> {
                    for (j in 0 until height) {
                        System.arraycopy(bytes, srcIndex, yBytes, dstIndex, width)
                        srcIndex += rowStride
                        dstIndex += width
                    }
                }
                1 -> {
                    for (j in 0 until height / 2) {
                        for (k in 0 until width / 2) {
                            uBytes[dstIndex++] = bytes[srcIndex]
                            srcIndex += pixelStride
                        }
                        if (pixelStride == 2) {
                            srcIndex += rowStride - width
                        } else if (pixelStride == 1) {
                            srcIndex += rowStride - width / 2
                        }
                    }
                }
                2 -> {
                    for (j in 0 until height / 2) {
                        for (k in 0 until width / 2) {
                            vBytes[dstIndex++] = bytes[srcIndex]
                            srcIndex += pixelStride
                        }
                        if (pixelStride == 2) {
                            srcIndex += rowStride - width
                        } else if (pixelStride == 1) {
                            srcIndex += rowStride - width / 2
                        }
                    }
                }
            }
            System.arraycopy(yBytes, 0, i420, 0, yBytes.size)
            System.arraycopy(uBytes, 0, i420, yBytes.size, uBytes.size)
            System.arraycopy(vBytes, 0, i420, yBytes.size + uBytes.size, vBytes.size)
            onPreviewListener?.onPreviewFrame(i420, i420.size)
        }
        image.close()
    }

    fun setPreviewSizeListener(onPreviewSizeListener: OnPreviewSizeListener?) {
        this.onPreviewSizeListener = onPreviewSizeListener
    }

    fun setOnPreviewListener(onPreviewListener: OnPreviewListener?) {
        this.onPreviewListener = onPreviewListener
    }

    fun switchAWB(){
        println(awbModes.size)
        currentAWBIdx = (currentAWBIdx + 1) % awbModes.size
        currentAWB = awbModes[currentAWBIdx]
        previewRequestBuilder!!.set(
            CaptureRequest.CONTROL_AWB_MODE,
            currentAWB
        )
        previewRequest = previewRequestBuilder!!.build()
        cameraCaptureSession!!.setRepeatingRequest(
            previewRequest!!,
            captureCallbackPhoto, cameraHandler
        )
    }

    fun getCurrentAWB(): Int {
        return currentAWB
    }

    interface OnPreviewSizeListener {
        fun onSize(width: Int, height: Int)
    }

    interface OnPreviewListener {
        fun onPreviewFrame(data: ByteArray?, len: Int)
    }

    companion object {
        private val TAG = CameraFragment::class.java.simpleName
        /** 照片格式 */
        private const val PIXEL_FORMAT_PHOTO = ImageFormat.JPEG
        /** 视频格式 */
        private const val PIXEL_FORMAT_VIDEO = ImageFormat.YUV_420_888

        /** Maximum number of images that will be held in the reader's buffer */
        private const val IMAGE_BUFFER_SIZE: Int = 3

        /** Maximum time allowed to wait for the result of an image capture */
        private const val IMAGE_CAPTURE_TIMEOUT_MILLIS: Long = 5000

        /** Helper data class used to hold capture metadata with their associated image */
        data class CombinedCaptureResult(
            val image: Image,
            val metadata: CaptureResult,
            val orientation: Int,
            val format: Int
        ) : Closeable {
            override fun close() = image.close()
        }

        /**
         * Create a [File] named a using formatted timestamp with the current date and time.
         *
         * @return [File] created.
         */
        private fun createFile(context: Context, extension: String): File {
            val sdf = SimpleDateFormat("yyyy_MM_dd_HH_mm_ss_SSS", Locale.CHINA)
            return File(context.filesDir, "IMG_${sdf.format(Date())}.$extension")
        }

        private fun chooseOptimalSize(
            choices: Array<Size>, textureViewWidth: Int,
            textureViewHeight: Int, maxWidth: Int, maxHeight: Int, aspectRatio: Size
        ): Size {

            // Collect the supported resolutions that are at least as big as the preview Surface
            val bigEnough: MutableList<Size> = ArrayList()
            // Collect the supported resolutions that are smaller than the preview Surface
            val notBigEnough: MutableList<Size> = ArrayList()
            val w = aspectRatio.width
            val h = aspectRatio.height
            for (option in choices) {
                if (option.width <= maxWidth && option.height <= maxHeight && option.height == option.width * h / w) {
                    if (option.width >= textureViewWidth &&
                        option.height >= textureViewHeight
                    ) {
                        bigEnough.add(option)
                    } else {
                        notBigEnough.add(option)
                    }
                }
            }

            // Pick the smallest of those big enough. If there is no one big enough, pick the
            // largest of those not big enough.
            return if (bigEnough.size > 0) {
                Collections.min<Size>(bigEnough, CompareSizesByArea())
            } else if (notBigEnough.size > 0) {
                Collections.max<Size>(notBigEnough, CompareSizesByArea())
            } else {
                Log.e("Camera2Helper", "Couldn't find any suitable preview size")
                choices[0]
            }
        }

        internal class CompareSizesByArea : Comparator<Size> {
            override fun compare(lhs: Size, rhs: Size): Int {
                // We cast here to ensure the multiplications won't overflow
                return java.lang.Long.signum(
                    lhs.width.toLong() * lhs.height -
                            rhs.width.toLong() * rhs.height
                )
            }
        }
    }

}

